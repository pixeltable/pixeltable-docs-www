---
title: "openai"
icon: "square-m"
description: "<a href=\"https://github.com/pixeltable/pixeltable/blob/main/pixeltable/functions/openai.py#L0\" id=\"viewSource\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/View%20Source%20on%20Github-blue?logo=github&labelColor=gray\" alt=\"View Source on GitHub\" style={{ display: 'inline', margin: '0px' }} noZoom /></a>"
---
# <span style={{ 'color': 'gray' }}>module</span>&nbsp; pixeltable.functions.openai


Pixeltable UDFs
that wrap various endpoints from the OpenAI API. In order to use them, you must
first `pip install openai` and configure your OpenAI credentials, as described in
the [Working with OpenAI](https://docs.pixeltable.com/notebooks/integrations/working-with-openai) tutorial.


## <span style={{ 'color': 'gray' }}>func</span>&nbsp; invoke_tools()

```python Signature
invoke_tools(
    tools: pixeltable.func.tools.Tools,
    response: pixeltable.exprs.expr.Expr
) -> pixeltable.exprs.inline_expr.InlineDict
```

Converts an OpenAI response dict to Pixeltable tool invocation format and calls `tools._invoke()`.


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; chat_completions()

```python Signature
@pxt.udf
chat_completions(
    messages: pxt.Json,
    *,
    model: pxt.String,
    model_kwargs: pxt.Json | None = None,
    tools: pxt.Json | None = None,
    tool_choice: pxt.Json | None = None
) -> pxt.Json
```

Creates a model response for the given chat conversation.

Equivalent to the OpenAI `chat/completions` API endpoint.
For additional details, see: [https://platform.openai.com/docs/guides/chat-completions](https://platform.openai.com/docs/guides/chat-completions)

Request throttling:
Uses the rate limit-related headers returned by the API to throttle requests adaptively, based on available
request and token capacity. No configuration is necessary.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`messages`** (`pxt.Json`): A list of messages to use for chat completion, as described in the OpenAI API documentation.
- **`model`** (`pxt.String`): The model to use for chat completion.
- **`model_kwargs`** (`pxt.Json | None`): Additional keyword args for the OpenAI `chat/completions` API. For details on the available
    parameters, see: [https://platform.openai.com/docs/api-reference/chat/create](https://platform.openai.com/docs/api-reference/chat/create)

**Returns:**

- `pxt.Json`: A dictionary containing the response and other metadata.

**Examples:**

Add a computed column that applies the model `gpt-4o-mini` to an existing Pixeltable column `tbl.prompt` of the table `tbl`:
```python
messages = [
    {'role': 'system', 'content': 'You are a helpful assistant.'},
    {'role': 'user', 'content': tbl.prompt},
]
tbl.add_computed_column(
    response=chat_completions(messages, model='gpt-4o-mini')
)
```


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; embeddings()

```python Signature
@pxt.udf
embeddings(
    input: pxt.String,
    *,
    model: pxt.String,
    model_kwargs: pxt.Json | None = None
) -> pxt.Array[(None,), float32]
```

Creates an embedding vector representing the input text.

Equivalent to the OpenAI `embeddings` API endpoint.
For additional details, see: [https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings)

Request throttling:
Uses the rate limit-related headers returned by the API to throttle requests adaptively, based on available
request and token capacity. No configuration is necessary.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`input`** (`pxt.String`): The text to embed.
- **`model`** (`pxt.String`): The model to use for the embedding.
- **`model_kwargs`** (`pxt.Json | None`): Additional keyword args for the OpenAI `embeddings` API. For details on the available
    parameters, see: [https://platform.openai.com/docs/api-reference/embeddings](https://platform.openai.com/docs/api-reference/embeddings)

**Returns:**

- `pxt.Array[(None,), float32]`: An array representing the application of the given embedding to `input`.

**Examples:**

Add a computed column that applies the model `text-embedding-3-small` to an existing Pixeltable column `tbl.text` of the table `tbl`:
```python
tbl.add_computed_column(
    embed=embeddings(tbl.text, model='text-embedding-3-small')
)
```

Add an embedding index to an existing column `text`, using the model `text-embedding-3-small`:
```python
tbl.add_embedding_index(
    embedding=embeddings.using(model='text-embedding-3-small')
)
```


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; image_generations()

```python Signature
@pxt.udf
image_generations(
    prompt: pxt.String,
    *,
    model: pxt.String = 'dall-e-2',
    model_kwargs: pxt.Json | None = None
) -> pxt.Image
```

Creates an image given a prompt.

Equivalent to the OpenAI `images/generations` API endpoint.
For additional details, see: [https://platform.openai.com/docs/guides/images](https://platform.openai.com/docs/guides/images)

Request throttling:
Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate
limit is configured, uses a default of 600 RPM.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`prompt`** (`pxt.String`): Prompt for the image.
- **`model`** (`pxt.String`): The model to use for the generations.
- **`model_kwargs`** (`pxt.Json | None`): Additional keyword args for the OpenAI `images/generations` API. For details on the available
    parameters, see: [https://platform.openai.com/docs/api-reference/images/create](https://platform.openai.com/docs/api-reference/images/create)

**Returns:**

- `pxt.Image`: The generated image.

**Examples:**

Add a computed column that applies the model `dall-e-2` to an existing Pixeltable column `tbl.text` of the table `tbl`:
```python
tbl.add_computed_column(
    gen_image=image_generations(tbl.text, model='dall-e-2')
)
```


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; moderations()

```python Signature
@pxt.udf
moderations(
    input: pxt.String,
    *,
    model: pxt.String = 'omni-moderation-latest'
) -> pxt.Json
```

Classifies if text is potentially harmful.

Equivalent to the OpenAI `moderations` API endpoint.
For additional details, see: [https://platform.openai.com/docs/guides/moderation](https://platform.openai.com/docs/guides/moderation)

Request throttling:
Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate
limit is configured, uses a default of 600 RPM.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`input`** (`pxt.String`): Text to analyze with the moderations model.
- **`model`** (`pxt.String`): The model to use for moderations.

**Returns:**

- `pxt.Json`: Details of the moderations results.

**Examples:**

Add a computed column that applies the model `text-moderation-stable` to an existing Pixeltable column `tbl.input` of the table `tbl`:
```python
tbl.add_computed_column(
    moderations=moderations(tbl.text, model='text-moderation-stable')
)
```


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; speech()

```python Signature
@pxt.udf
speech(
    input: pxt.String,
    *,
    model: pxt.String,
    voice: pxt.String,
    model_kwargs: pxt.Json | None = None
) -> pxt.Audio
```

Generates audio from the input text.

Equivalent to the OpenAI `audio/speech` API endpoint.
For additional details, see: [https://platform.openai.com/docs/guides/text-to-speech](https://platform.openai.com/docs/guides/text-to-speech)

Request throttling:
Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate
limit is configured, uses a default of 600 RPM.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`input`** (`pxt.String`): The text to synthesize into speech.
- **`model`** (`pxt.String`): The model to use for speech synthesis.
- **`voice`** (`pxt.String`): The voice profile to use for speech synthesis. Supported options include:
    `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`.
- **`model_kwargs`** (`pxt.Json | None`): Additional keyword args for the OpenAI `audio/speech` API. For details on the available
    parameters, see: [https://platform.openai.com/docs/api-reference/audio/createSpeech](https://platform.openai.com/docs/api-reference/audio/createSpeech)

**Returns:**

- `pxt.Audio`: An audio file containing the synthesized speech.

**Examples:**

Add a computed column that applies the model `tts-1` to an existing Pixeltable column `tbl.text` of the table `tbl`:
```python
tbl.add_computed_column(
    audio=speech(tbl.text, model='tts-1', voice='nova')
)
```


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; transcriptions()

```python Signature
@pxt.udf
transcriptions(
    audio: pxt.Audio,
    *,
    model: pxt.String,
    model_kwargs: pxt.Json | None = None
) -> pxt.Json
```

Transcribes audio into the input language.

Equivalent to the OpenAI `audio/transcriptions` API endpoint.
For additional details, see: [https://platform.openai.com/docs/guides/speech-to-text](https://platform.openai.com/docs/guides/speech-to-text)

Request throttling:
Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate
limit is configured, uses a default of 600 RPM.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`audio`** (`pxt.Audio`): The audio to transcribe.
- **`model`** (`pxt.String`): The model to use for speech transcription.
- **`model_kwargs`** (`pxt.Json | None`): Additional keyword args for the OpenAI `audio/transcriptions` API. For details on the available
    parameters, see: [https://platform.openai.com/docs/api-reference/audio/createTranscription](https://platform.openai.com/docs/api-reference/audio/createTranscription)

**Returns:**

- `pxt.Json`: A dictionary containing the transcription and other metadata.

**Examples:**

Add a computed column that applies the model `whisper-1` to an existing Pixeltable column `tbl.audio` of the table `tbl`:
```python
tbl.add_computed_column(
    transcription=transcriptions(
        tbl.audio, model='whisper-1', language='en'
    )
)
```


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; translations()

```python Signature
@pxt.udf
translations(
    audio: pxt.Audio,
    *,
    model: pxt.String,
    model_kwargs: pxt.Json | None = None
) -> pxt.Json
```

Translates audio into English.

Equivalent to the OpenAI `audio/translations` API endpoint.
For additional details, see: [https://platform.openai.com/docs/guides/speech-to-text](https://platform.openai.com/docs/guides/speech-to-text)

Request throttling:
Applies the rate limit set in the config (section `openai.rate_limits`; use the model id as the key). If no rate
limit is configured, uses a default of 600 RPM.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`audio`** (`pxt.Audio`): The audio to translate.
- **`model`** (`pxt.String`): The model to use for speech transcription and translation.
- **`model_kwargs`** (`pxt.Json | None`): Additional keyword args for the OpenAI `audio/translations` API. For details on the available
    parameters, see: [https://platform.openai.com/docs/api-reference/audio/createTranslation](https://platform.openai.com/docs/api-reference/audio/createTranslation)

**Returns:**

- `pxt.Json`: A dictionary containing the translation and other metadata.

**Examples:**

Add a computed column that applies the model `whisper-1` to an existing Pixeltable column `tbl.audio` of the table `tbl`:
```python
tbl.add_computed_column(
    translation=translations(tbl.audio, model='whisper-1', language='en')
)
```


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; vision()

```python Signature
@pxt.udf
vision(
    prompt: pxt.String,
    image: pxt.Image,
    *,
    model: pxt.String,
    model_kwargs: pxt.Json | None = None
) -> pxt.String
```

Analyzes an image with the OpenAI vision capability. This is a convenience function that takes an image and
prompt, and constructs a chat completion request that utilizes OpenAI vision.

For additional details, see: [https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)

Request throttling:
Uses the rate limit-related headers returned by the API to throttle requests adaptively, based on available
request and token capacity. No configuration is necessary.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`prompt`** (`pxt.String`): A prompt for the OpenAI vision request.
- **`image`** (`pxt.Image`): The image to analyze.
- **`model`** (`pxt.String`): The model to use for OpenAI vision.

**Returns:**

- `pxt.String`: The response from the OpenAI vision API.

**Examples:**

Add a computed column that applies the model `gpt-4o-mini` to an existing Pixeltable column `tbl.image` of the table `tbl`:
```python
tbl.add_computed_column(
    response=vision(
        "What's in this image?", tbl.image, model='gpt-4o-mini'
    )
)
```

