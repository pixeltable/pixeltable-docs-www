---
title: "pixeltable.functions.openrouter"
sidebarTitle: "openrouter"
icon: "square-m"
---
<a href="https://github.com/pixeltable/pixeltable/blob/main/pixeltable/functions/openrouter.py#L0" target="_blank">View source on GitHub</a>


Pixeltable UDFs that wrap the OpenRouter API.

OpenRouter provides a unified interface to multiple LLM providers. In order to use it, you must first sign up at https://openrouter.ai, create an API key, and configure it as described in the Working with OpenRouter tutorial.



## udf `chat_completions()`

```python
chat_completions(
    messages: Json,
    *,
    model: String,
    model_kwargs: Json | None = None,
    tools: Json | None = None,
    tool_choice: Json | None = None,
    provider: Json | None = None,
    transforms: Json | None = None
) -> Json
```

Chat Completion API via OpenRouter.


OpenRouter provides access to multiple LLM providers through a unified API. For additional details, see: [https://openrouter.ai/docs](https://openrouter.ai/docs)

Supported models can be found at: [https://openrouter.ai/models](https://openrouter.ai/models)

Request throttling: Applies the rate limit set in the config (section `openrouter`, key `rate_limit`). If no rate limit is configured, uses a default of 600 RPM.

**Requirements:**

- `pip install openai`


**Parameters:**

- **`messages`** (`Json`): A list of messages comprising the conversation so far.
- **`model`** (`String`): ID of the model to use (e.g., 'anthropic/claude-3.5-sonnet', 'openai/gpt-4').
- **`model_kwargs`** (`Json | None`): Additional OpenAI-compatible parameters.
- **`tools`** (`Json | None`): List of tools available to the model.
- **`tool_choice`** (`Json | None`): Controls which (if any) tool is called by the model.
- **`provider`** (`Json | None`): OpenRouter-specific provider preferences (e.g., \{'order': \['Anthropic', 'OpenAI'\]\}).
- **`transforms`** (`Json | None`): List of message transforms to apply (e.g., \['middle-out'\]).

**Returns:**

- `Json`: A dictionary containing the response in OpenAI format.

**Example:**

Basic chat completion:
```python
messages = [{'role': 'user', 'content': tbl.prompt}]
tbl.add_computed_column(response=chat_completions(messages, model='anthropic/claude-3.5-sonnet'))
```

With provider routing:
```python
tbl.add_computed_column(
    response=chat_completions(
        messages, model='anthropic/claude-3.5-sonnet', provider={'require_parameters': True, 'order': ['Anthropic']}
    )
)
```

With transforms:
```python
tbl.add_computed_column(
    response=chat_completions(
        messages,
        model='openai/gpt-4',
        transforms=['middle-out'],  # Optimize for long contexts
    )
)
```

