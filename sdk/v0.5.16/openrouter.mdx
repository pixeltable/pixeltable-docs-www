---
title: "openrouter"
icon: "square-m"
description: "<a href=\"https://github.com/pixeltable/pixeltable/blob/main/pixeltable/functions/openrouter.py#L0\" id=\"viewSource\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/View%20Source%20on%20Github-blue?logo=github&labelColor=gray\" alt=\"View Source on GitHub\" style={{ display: 'inline', margin: '0px' }} noZoom /></a>"
noindex: true
---
# <span style={{ 'color': 'gray' }}>module</span>&nbsp; pixeltable.functions.openrouter


Pixeltable UDFs that wrap the OpenRouter API.

OpenRouter provides a unified interface to multiple LLM providers. In order to use it,
you must first sign up at https://openrouter.ai, create an API key, and configure it
as described in the Working with OpenRouter tutorial.


## <span style={{ 'color': 'gray' }}>udf</span>&nbsp; chat_completions()

```python Signature
@pxt.udf
chat_completions(
    messages: pxt.Json,
    *,
    model: pxt.String,
    model_kwargs: pxt.Json | None = None,
    tools: pxt.Json | None = None,
    tool_choice: pxt.Json | None = None,
    provider: pxt.Json | None = None,
    transforms: pxt.Json | None = None
) -> pxt.Json
```

Chat Completion API via OpenRouter.

OpenRouter provides access to multiple LLM providers through a unified API.
For additional details, see: [https://openrouter.ai/docs](https://openrouter.ai/docs)

Supported models can be found at: [https://openrouter.ai/models](https://openrouter.ai/models)

Request throttling:
Applies the rate limit set in the config (section `openrouter`, key `rate_limit`). If no rate
limit is configured, uses a default of 600 RPM.

__Requirements:__

- `pip install openai`

**Parameters:**

- **`messages`** (`pxt.Json`): A list of messages comprising the conversation so far.
- **`model`** (`pxt.String`): ID of the model to use (e.g., `'anthropic/claude-3.5-sonnet'`, `'openai/gpt-4'`).
- **`model_kwargs`** (`pxt.Json | None`): Additional OpenAI-compatible parameters.
- **`tools`** (`pxt.Json | None`): List of tools available to the model.
- **`tool_choice`** (`pxt.Json | None`): Controls which (if any) tool is called by the model.
- **`provider`** (`pxt.Json | None`): OpenRouter-specific provider preferences (e.g., `{'order': ['Anthropic', 'OpenAI']}`).
- **`transforms`** (`pxt.Json | None`): List of message transforms to apply (e.g., `['middle-out']`).

**Returns:**

- `pxt.Json`: A dictionary containing the response in OpenAI format.

**Examples:**

Basic chat completion:
```python
messages = [{'role': 'user', 'content': tbl.prompt}]
tbl.add_computed_column(
    response=chat_completions(
        messages, model='anthropic/claude-3.5-sonnet'
    )
)
```

With provider routing:
```python
tbl.add_computed_column(
    response=chat_completions(
        messages,
        model='anthropic/claude-3.5-sonnet',
        provider={'require_parameters': True, 'order': ['Anthropic']},
    )
)
```

With transforms:
```python
tbl.add_computed_column(
    response=chat_completions(
        messages,
        model='openai/gpt-4',
        transforms=['middle-out'],  # Optimize for long contexts
    )
)
```

