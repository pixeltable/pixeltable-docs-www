---
title: "Detect objects in images"
sidebarTitle: "Detect objects in images"
icon: "notebook"
---
<a href="https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/release/docs/release/howto/cookbooks/images/img-detect-objects.ipynb" id="openKaggle" target="_blank" rel="noopener noreferrer"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open in Kaggle" style={{ display: 'inline', margin: '0px' }} noZoom /></a>&nbsp;&nbsp;<a href="https://colab.research.google.com/github/pixeltable/pixeltable/blob/release/docs/release/howto/cookbooks/images/img-detect-objects.ipynb" id="openColab" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab" style={{ display: 'inline', margin: '0px' }} noZoom /></a>&nbsp;&nbsp;<a href="https://raw.githubusercontent.com/pixeltable/pixeltable/refs/tags/release/docs/release/howto/cookbooks/images/img-detect-objects.ipynb" id="downloadNotebook" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%E2%AC%87-Download%20Notebook-blue" alt="Download Notebook" style={{ display: 'inline', margin: '0px' }} noZoom /></a>

<Tip>This documentation page is also available as an interactive notebook. You can launch the notebook in
Kaggle or Colab, or download it for use with an IDE or local Jupyter installation, by clicking one of the
above links.</Tip>




export const quartoRawHtml =
[`
<table>
<thead>
<tr>
<th>Use case</th>
<th>Images</th>
<th>Need</th>
</tr>
</thead>
<tbody>
<tr>
<td style="vertical-align: middle;">Inventory counting</td>
<td style="vertical-align: middle;">5K product photos</td>
<td style="vertical-align: middle;">Count items per image</td>
</tr>
<tr>
<td style="vertical-align: middle;">Security monitoring</td>
<td style="vertical-align: middle;">10K frames</td>
<td style="vertical-align: middle;">Detect people, vehicles</td>
</tr>
<tr>
<td style="vertical-align: middle;">Quality control</td>
<td style="vertical-align: middle;">20K inspection images</td>
<td style="vertical-align: middle;">Find defects</td>
</tr>
</tbody>
</table>
`,`
<table>
<thead>
<tr>
<th>Model</th>
<th>Speed</th>
<th>Accuracy</th>
<th>Use case</th>
</tr>
</thead>
<tbody>
<tr>
<td style="vertical-align: middle;"><code>yolox_nano</code></td>
<td style="vertical-align: middle;">Fastest</td>
<td style="vertical-align: middle;">Lower</td>
<td style="vertical-align: middle;">Real-time, edge devices</td>
</tr>
<tr>
<td style="vertical-align: middle;"><code>yolox_tiny</code></td>
<td style="vertical-align: middle;">Fast</td>
<td style="vertical-align: middle;">Good</td>
<td style="vertical-align: middle;">Mobile, quick processing</td>
</tr>
<tr>
<td style="vertical-align: middle;"><code>yolox_s</code></td>
<td style="vertical-align: middle;">Medium</td>
<td style="vertical-align: middle;">Better</td>
<td style="vertical-align: middle;">Balanced performance</td>
</tr>
<tr>
<td style="vertical-align: middle;"><code>yolox_m</code></td>
<td style="vertical-align: middle;">Slower</td>
<td style="vertical-align: middle;">High</td>
<td style="vertical-align: middle;">General use (recommended)</td>
</tr>
<tr>
<td style="vertical-align: middle;"><code>yolox_l</code></td>
<td style="vertical-align: middle;">Slow</td>
<td style="vertical-align: middle;">Higher</td>
<td style="vertical-align: middle;">High accuracy needs</td>
</tr>
<tr>
<td style="vertical-align: middle;"><code>yolox_x</code></td>
<td style="vertical-align: middle;">Slowest</td>
<td style="vertical-align: middle;">Highest</td>
<td style="vertical-align: middle;">Maximum accuracy</td>
</tr>
</tbody>
</table>
`];

Automatically identify and locate objects in images using YOLOX object
detection models.

## Problem

You have images that need object detection—identifying what objects are
present and where they’re located. Manual labeling is slow and
expensive.

<div style={{ 'margin': '0px 20px 0px 20px' }} dangerouslySetInnerHTML={{ __html: quartoRawHtml[0] }} />

## Solution

**What’s in this recipe:** - Detect objects using YOLOX models (runs
locally, no API needed) - Get bounding boxes and class labels - Filter
detections by confidence threshold

You add a computed column that runs YOLOX on each image. Detection
happens automatically when you insert new images.

### Setup


```python
%pip install -qU pixeltable pixeltable-yolox

```


```python
import pixeltable as pxt
from pixeltable.functions.yolox import yolox

```

### Load images


```python
# Create a fresh directory
pxt.drop_dir('detection_demo', force=True)
pxt.create_dir('detection_demo')

```


```python
# Create table for images
images = pxt.create_table('detection_demo.images', {'image': pxt.Image})

```


```python
# Insert sample images (COCO dataset samples with common objects)
image_urls = [
    'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000036.jpg',
    'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000090.jpg',
    'https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/resources/images/000000000106.jpg',
]

images.insert([{'image': url} for url in image_urls])

```


```python
# View images
images.collect()

```

### Run object detection

Add a computed column that runs YOLOX on each image:


```python
# Run YOLOX object detection
# model_id options: yolox_nano, yolox_tiny, yolox_s, yolox_m, yolox_l, yolox_x
images.add_computed_column(
    detections=yolox(images.image, model_id='yolox_m', threshold=0.5)
)

```


```python
# View detection results
images.select(images.image, images.detections).collect()

```

### Extract detection details

Parse the detection output to get object counts and classes:


```python
# Extract number of detections
@pxt.udf
def count_objects(detections: dict) -> int:
    """Count the number of detected objects."""
    return len(detections.get('labels', []))

images.add_computed_column(object_count=count_objects(images.detections))

```


```python
# Extract unique object classes
@pxt.udf
def get_classes(detections: dict) -> list:
    """Get list of detected object classes."""
    return list(set(detections.get('labels', [])))

images.add_computed_column(object_classes=get_classes(images.detections))

```


```python
# View summary
images.select(images.image, images.object_count, images.object_classes).collect()

```

## Explanation

**YOLOX model sizes:**

<div style={{ 'margin': '0px 20px 0px 20px' }} dangerouslySetInnerHTML={{ __html: quartoRawHtml[1] }} />

**Detection output format:**

The `detections` dictionary contains: - `labels`: List of class names
(e.g., “person”, “car”, “dog”) - `boxes`: Bounding box coordinates \[x1,
y1, x2, y2\] - `scores`: Confidence scores (0-1)

**Adjusting threshold:**

-   Higher threshold (0.7-0.9): Fewer detections, higher confidence
-   Lower threshold (0.3-0.5): More detections, may include false
    positives

## See also

-   [Extract frames from
    videos](/howto/cookbooks/video/video-extract-frames) -
    Detect objects in video frames
-   [Analyze images in
    batch](/howto/cookbooks/images/vision-batch-analysis) -
    AI vision analysis
-   [Find similar
    images](/howto/cookbooks/search/search-similar-images) -
    Visual similarity search
